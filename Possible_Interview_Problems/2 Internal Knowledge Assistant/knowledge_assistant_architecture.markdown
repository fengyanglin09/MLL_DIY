# Internal Knowledge Assistant System Architecture

## Problem Statement
Employees struggle to find information across Confluence, Google Drive, and Slack. The goal is to build a centralized **Internal Knowledge Assistant** that:
- Enables semantic search using Retrieval-Augmented Generation (RAG) with vector databases.
- Supports secure user authentication and role-based access control (RBAC).
- Indexes documents from multiple sources (Confluence, Google Drive, Slack).
- Prioritizes recent information with temporal relevance.
- Leverages a Foundational Model for natural language understanding and generation.

This document outlines a system architecture using **Angular** (frontend), **FastAPI** (backend), and **Google Cloud Platform (GCP)** (infrastructure) to meet these requirements.

---

## System Architecture Overview

The system integrates Confluence, Google Drive, and Slack, providing a unified search interface with semantic search, natural language answers, and secure access. It:
1. Indexes documents from multiple sources.
2. Stores embeddings in a vector database for semantic search.
3. Uses RAG to combine vector search with a Foundational Model for natural language responses.
4. Implements user authentication and RBAC for secure access.
5. Prioritizes recent information in search results.

### High-Level Architecture Diagram
```
[Users]
   |
[Angular Frontend (Web App)]
   | HTTP/REST (JSON)
[FastAPI Backend]
   | Integrations: Confluence, Google Drive, Slack APIs
   | Authentication: Firebase Authentication
   | Vector DB: GCP Firestore (or Pinecone on GCP)
   | Foundational Model: Vertex AI (GCP-hosted model, e.g., PaLM 2)
   | Storage: Cloud Storage (for raw documents, if needed)
[GCP Infrastructure]
   | Cloud Run (FastAPI deployment)
   | Firebase (Authentication & RBAC)
   | Firestore (Vector storage or metadata)
   | Cloud Scheduler (Periodic indexing)
   | Secret Manager (API keys, credentials)
   | Vertex AI (Foundational Model hosting)
```

---

## Requirements and Component Breakdown

### Requirements
1. **RAG with Vector DBs**: Enable semantic search across documents using embeddings and augment results with a Foundational Model for natural language responses.
2. **User Authentication and Role-Based Access**: Authenticate users securely and restrict document access based on roles/permissions.
3. **Multi-Source Document Indexing**: Ingest and index content from Confluence, Google Drive, and Slack.
4. **Temporal Relevance**: Prioritize recent information in search results.

### Components and Explanations

#### 1. **Angular (Frontend)**
**Purpose**: Provides a responsive, user-friendly web interface for employees to search and interact with the Knowledge Assistant.

**How It Meets Requirements**:
- **RAG with Vector DBs**:
  - Handles user input (search queries) and displays results, including answers generated by the Foundational Model.
  - Uses Angular’s HTTP client to communicate with the FastAPI backend.
  - Supports dynamic UI components for document snippets, metadata, and relevance indicators.
- **User Authentication and Role-Based Access**:
  - Integrates with Firebase Authentication’s client-side SDK for user login (e.g., Google SSO).
  - Displays role-specific content based on permissions fetched from the backend.
- **Multi-Source Document Indexing**:
  - Provides a UI to trigger manual re-indexing or display indexing status.
- **Temporal Relevance**:
  - Displays document metadata (e.g., last modified date) in search results.
  - Can sort or highlight results based on backend-provided relevance scores.

**Why Angular?**
- Component-based architecture for modular, scalable frontend.
- Strong TypeScript support for robust code.
- Seamless integration with Firebase Authentication.
- Responsive design for accessibility across devices.

#### 2. **FastAPI (Backend)**
**Purpose**: Serves as the API layer to handle search requests, integrate with external services, manage authentication, and orchestrate RAG with the Foundational Model.

**How It Meets Requirements**:
- **RAG with Vector DBs**:
  - Implements RAG pipeline:
    1. Receives user query via REST API.
    2. Queries vector database (Firestore or Pinecone) for relevant document embeddings using embeddings generated by the Foundational Model.
    3. Retrieves top-k documents and passes them to the Foundational Model (via Vertex AI) for natural language answers.
  - Uses Python libraries (e.g., `langchain`, `transformers`) for embedding generation and RAG.
- **User Authentication and Role-Based Access**:
  - Integrates with Firebase Authentication to verify user tokens (JWT).
  - Enforces RBAC by checking user roles against document permissions.
  - Filters search results based on user access.
- **Multi-Source Document Indexing**:
  - Fetches content via APIs:
    - **Confluence**: Atlassian REST API for pages and attachments.
    - **Google Drive**: Google Drive API for files (Docs, Sheets, PDFs).
    - **Slack**: Slack API for messages, threads, and files.
  - Processes documents (e.g., extracts text from PDFs) using libraries like `PyPDF2` or Google Cloud Document AI.
  - Generates embeddings using the Foundational Model and stores them in the vector DB.
- **Temporal Relevance**:
  - Stores document metadata (e.g., `last_modified`) in the vector DB.
  - Applies recency boost in search (e.g., hybrid scoring: `score = semantic_similarity + recency_weight * (current_time - last_modified)`).

**Why FastAPI?**
- High-performance, async Python framework for REST APIs.
- Pydantic for robust data validation.
- Easy integration with NLP libraries and GCP services.
- Simplifies authentication middleware and RBAC.

#### 3. **GCP Infrastructure**
**Purpose**: Provides scalable, secure cloud services for hosting, storage, authentication, vector storage, Foundational Model inference, and scheduling.

**Components and How They Meet Requirements**:

##### a. **Cloud Run (Hosting FastAPI)**
- **Purpose**: Deploys FastAPI as a serverless container.
- **How It Helps**:
  - Scales for RAG and indexing workloads.
  - Cost-effective for variable traffic.
- **Why**: Serverless, auto-scaling, and managed.

##### b. **Firebase Authentication (User Authentication)**
- **Purpose**: Manages user authentication and supports RBAC.
- **How It Helps**:
  - Provides secure authentication (Google SSO, email/password).
  - Stores user roles in custom claims or Firestore for RBAC.
  - Verifies JWT tokens.
- **Why**: Easy integration with Angular and FastAPI, enterprise-grade SSO.

##### c. **Firestore (Vector DB or Metadata Storage)**
- **Purpose**: Stores document metadata and optionally embeddings.
- **How It Helps**:
  - Stores embeddings or metadata (document ID, source, permissions, last_modified).
  - Supports fast metadata queries for RBAC and recency.
- **Why**: Fully managed, scalable, integrates with Firebase/GCP.

##### d. **Pinecone (Optional Vector DB)**
- **Purpose**: Dedicated vector database for embeddings (if Firestore is insufficient).
- **How It Helps**:
  - Optimized for vector similarity search.
  - Scales for large document sets.
- **Why**: Purpose-built for vector search, hosted on GCP.

##### e. **Vertex AI with Foundational Model (Embeddings and Natural Language Generation)**
- **Purpose**: Hosts the Foundational Model (e.g., PaLM 2) for embeddings and LLM inference in the RAG pipeline.
- **How It Helps**:
  - **RAG with Vector DBs**:
    - The Foundational Model generates embeddings for documents and queries using a model like `text-embedding-gecko`.
    - It also performs natural language generation, producing coherent answers from retrieved documents.
  - **Multi-Source Document Indexing**:
    - Embeds document content for storage in the vector DB.
- **Why**: Vertex AI provides a managed environment for the Foundational Model, offering enterprise-grade performance and scalability for NLP tasks.

##### f. **Cloud Storage (Document Storage)**
- **Purpose**: Stores raw documents or large files.
- **How It Helps**:
  - Stores files from Google Drive/Confluence for processing.
- **Why**: Scalable, cost-effective, integrates with Document AI.

##### g. **Cloud Scheduler (Indexing Automation)**
- **Purpose**: Schedules periodic indexing.
- **How It Helps**:
  - Triggers FastAPI indexing endpoints.
  - Ensures recent documents are indexed.
- **Why**: Managed cron job service.

##### h. **Secret Manager (Credential Management)**
- **Purpose**: Stores API keys and credentials.
- **How It Helps**:
  - Secure access to Confluence, Google Drive, Slack APIs.
  - Stores Firebase service account keys.
- **Why**: Secure, centralized, integrates with FastAPI/Cloud Run.

---

## Workflow Example
1. **User Interaction**:
   - Employee logs in via Angular (Firebase, Google SSO).
   - Enters query (e.g., “recent project updates”).
   - Angular sends query to FastAPI.
2. **Search and RAG**:
   - FastAPI verifies JWT and fetches user role/permissions.
   - Generates query embedding using the Foundational Model (Vertex AI).
   - Queries vector DB, filters by permissions, boosts by recency.
   - Passes top-k documents to the Foundational Model for answer generation.
   - Returns snippets and answer to Angular.
3. **Indexing**:
   - Cloud Scheduler triggers FastAPI indexing nightly.
   - FastAPI fetches new/updated content from APIs.
   - Processes documents, generates embeddings using the Foundational Model, stores in vector DB.
4. **Security**:
   - Firebase ensures authorized access.
   - FastAPI checks document permissions.

---

## Why This Architecture?
- **Angular**: Modern, responsive UI with TypeScript support.
- **FastAPI**: High-performance backend, integrates with NLP and GCP.
- **GCP**: Scalable, secure, managed services, including hosting the Foundational Model on Vertex AI.
- **Meets Requirements**:
  - RAG: Pinecone/Firestore + Foundational Model (Vertex AI) for semantic search.
  - Authentication/RBAC: Firebase + FastAPI.
  - Multi-Source Indexing: FastAPI + Cloud Scheduler.
  - Temporal Relevance: Metadata + hybrid scoring.

---

## Additional Considerations
- **Scalability**: Cloud Run and Firestore/Pinecone scale automatically.
- **Cost**: Use GCP cost calculator; optimize indexing.
- **Error Handling**: Retry logic for API failures.
- **Monitoring**: Cloud Monitoring/Logging for performance and errors.
- **Extensibility**: Add sources (e.g., Jira) by extending FastAPI.

This architecture provides a robust, scalable solution for the Internal Knowledge Assistant, addressing all specified requirements.