# Detailed Description of FastAPI Backend System Diagram

This document provides a detailed description of the system diagram for the **FastAPI Backend** of the Internal Knowledge Assistant, focusing on how its components handle the Retrieval-Augmented Generation (RAG) pipeline, authentication, document indexing, and temporal relevance. The diagram illustrates the internal modules of the FastAPI Backend, the tools/packages they rely on, and their interactions with external services like Google Cloud Platform (GCP) services and third-party APIs.

---

## Overview of the FastAPI Backend

The FastAPI Backend is the core of the Internal Knowledge Assistant, responsible for processing user search queries, managing authentication, indexing documents from multiple sources (Confluence, Google Drive, Slack), and ensuring search results are relevant and timely. It is built using **FastAPI**, a high-performance Python framework for REST APIs, and leverages various tools and external services to meet the system’s requirements:

1. **RAG with Vector DBs**: Semantic search using embeddings and natural language answers generated by a Foundational Model.
2. **User Authentication and Role-Based Access Control (RBAC)**: Secure user authentication and permission-based access to documents.
3. **Multi-Source Document Indexing**: Ingest and index content from Confluence, Google Drive, and Slack.
4. **Temporal Relevance**: Prioritize recent information in search results.

The diagram breaks the FastAPI Backend into four key modules:
- **RAG Pipeline Module**
- **Authentication Module**
- **Indexing Module**
- **Temporal Relevance Module**

Each module uses specific tools/packages and interacts with external services to fulfill its role. Below, we describe each element and how they function together.

---

## Diagram Elements and Their Functions

### 1. FastAPI Backend (Main Component)
The **FastAPI Backend** is the overarching component that encapsulates all backend functionality. It is built using the FastAPI framework, which provides a high-performance, asynchronous API server. The backend exposes REST endpoints (e.g., `/search`, `/index`) that the Angular Frontend interacts with via HTTP/REST (JSON) requests. It orchestrates the entire workflow, from user authentication to search result generation.

- **Role**: Serves as the central hub, coordinating the activities of its internal modules and external service integrations.
- **Interactions**:
  - Receives search queries from the Angular Frontend.
  - Delegates tasks to its internal modules (RAG Pipeline, Authentication, Indexing, Temporal Relevance).
  - Interacts with external services like GCP (e.g., Firestore, Vertex AI) and third-party APIs (e.g., Confluence API).

---

### 2. RAG Pipeline Module
The **RAG Pipeline Module** is responsible for implementing the Retrieval-Augmented Generation (RAG) pipeline, which enables semantic search and natural language responses using a Foundational Model.

- **Function**:
  - Receives a user query (e.g., “recent project updates for Q1 2025”) from the Angular Frontend via a `/search` endpoint.
  - Generates an embedding for the query using the Foundational Model hosted on Vertex AI.
  - Queries the vector database (Firestore or Pinecone) to retrieve the top-k documents whose embeddings are most similar to the query’s embedding.
  - Passes the retrieved documents to the Foundational Model to generate a natural language answer.
  - Returns the answer and document snippets to the Angular Frontend.
- **Tools/Packages**:
  - **`langchain`**: Used to orchestrate the RAG pipeline, including embedding generation, document retrieval, and interaction with the Foundational Model for answer generation.
  - **`google-cloud-aiplatform`**: Provides the Python SDK to interact with Vertex AI, where the Foundational Model (e.g., PaLM 2) is hosted.
- **External Interactions**:
  - **Vertex AI (Foundational Model)**: The module sends the query to Vertex AI to generate an embedding (e.g., using `text-embedding-gecko`) and later sends the top-k documents to the Foundational Model to generate a natural language answer (e.g., “The Q1 2025 project updates include…”).
  - **Firestore (Vector DB)**: Queries Firestore to retrieve document embeddings and metadata, filtering by user permissions.
  - **Pinecone (Optional Vector DB)**: If Firestore is insufficient for large-scale vector search, Pinecone is used as an alternative vector database.
  - **Authentication Module**: Before processing the query, the RAG Pipeline Module calls the Authentication Module to verify the user’s identity and permissions, ensuring only authorized documents are retrieved.
  - **Temporal Relevance Module**: Receives recency-boosted scores to prioritize recent documents in the final results.

---

### 3. Authentication Module
The **Authentication Module** ensures that all requests to the FastAPI Backend are secure and that users only access documents they are authorized to see, implementing user authentication and RBAC.

- **Function**:
  - Verifies the JWT token included in each request from the Angular Frontend.
  - Fetches the user’s role and permissions to enforce RBAC.
  - Filters search results and document access based on the user’s permissions.
- **Tools/Packages**:
  - **`firebase-admin`**: Provides the Python SDK to interact with Firebase Authentication, allowing the module to verify JWT tokens and fetch user roles.
- **External Interactions**:
  - **Firebase Authentication**: The module sends the JWT token to Firebase Authentication to verify the user’s identity and retrieve user metadata (e.g., user ID, email).
  - **Firestore (RBAC)**: Queries Firestore to fetch the user’s role and permissions (e.g., stored in a `users` collection with fields like `role` and `permissions`), which are used to filter search results.
- **Interactions with Other Modules**:
  - The **RAG Pipeline Module** relies on the Authentication Module to ensure that only documents the user has access to are included in search results. For example, if the user lacks permission to view HR documents, those documents are excluded from the vector database query.

---

### 4. Indexing Module
The **Indexing Module** is responsible for fetching, processing, and indexing documents from multiple sources (Confluence, Google Drive, Slack) to keep the vector database up-to-date.

- **Function**:
  - Periodically fetches new or updated content from external sources via their APIs.
  - Processes documents to extract text (e.g., from PDFs, Google Docs).
  - Generates embeddings for the documents using the Foundational Model.
  - Stores the embeddings and metadata (e.g., `document_id`, `source`, `permissions`, `last_modified`) in the vector database.
  - Optionally stores raw files in Cloud Storage for backup or further processing.
- **Tools/Packages**:
  - **`requests`**: A general-purpose HTTP library used to make API calls to external services.
  - **`atlassian-python-api`**: Simplifies interaction with the Confluence API to fetch pages and attachments.
  - **`slack_sdk`**: Provides a Python SDK to fetch messages, threads, and files from Slack.
  - **`google-api-python-client`**: Enables interaction with the Google Drive API to fetch files (Docs, Sheets, PDFs).
  - **`PyPDF2`**: Extracts text from PDF files fetched from Confluence or Google Drive.
  - **`Google Cloud Document AI`**: Processes complex documents (e.g., scanned PDFs, images) to extract text when `PyPDF2` is insufficient.
- **External Interactions**:
  - **Confluence API**: Fetches pages and attachments using the Atlassian REST API.
  - **Google Drive API**: Retrieves files (Docs, Sheets, PDFs) from Google Drive.
  - **Slack API**: Fetches messages, threads, and files from Slack channels.
  - **Secret Manager**: Retrieves API credentials (e.g., API keys, OAuth tokens) for Confluence, Google Drive, and Slack, ensuring secure authentication.
  - **Vertex AI (Foundational Model)**: Sends document text to the Foundational Model to generate embeddings for storage in the vector database.
  - **Firestore (Vector DB)**: Stores the generated embeddings and metadata (e.g., `last_modified`, `permissions`) for use in search.
  - **Pinecone (Optional Vector DB)**: If Firestore is not used, Pinecone stores embeddings for large-scale vector search.
  - **Cloud Storage**: Optionally stores raw documents (e.g., PDFs) for backup or further processing (e.g., with Document AI).
  - **Cloud Scheduler**: Triggers the indexing process by invoking the `/index` endpoint nightly, ensuring the vector database stays current.
- **Interactions with Other Modules**:
  - The Indexing Module indirectly supports the **RAG Pipeline Module** by ensuring the vector database contains up-to-date embeddings and metadata for search.
  - It also provides the **Temporal Relevance Module** with metadata (e.g., `last_modified`) for recency scoring.

---

### 5. Temporal Relevance Module
The **Temporal Relevance Module** ensures that search results prioritize recent information, addressing the requirement for temporal relevance.

- **Function**:
  - Fetches document metadata (e.g., `last_modified`) from the vector database.
  - Applies a recency boost to search results using a hybrid scoring formula: `score = semantic_similarity + recency_weight * (current_timestamp - last_modified)`.
  - Passes the adjusted scores to the RAG Pipeline Module to influence the final ranking of documents.
- **Tools/Packages**:
  - **`Custom Scoring Logic`**: A custom implementation within FastAPI that calculates the recency boost based on the `last_modified` timestamp and a configurable `recency_weight`.
- **External Interactions**:
  - **Firestore (Metadata)**: Retrieves document metadata, specifically the `last_modified` field, to calculate recency scores.
- **Interactions with Other Modules**:
  - The **RAG Pipeline Module** integrates the recency-boosted scores from the Temporal Relevance Module to prioritize recent documents in the top-k results before passing them to the Foundational Model for answer generation.
  - The **Indexing Module** provides the metadata (e.g., `last_modified`) that the Temporal Relevance Module uses for scoring.

---

### 6. External Services
The FastAPI Backend interacts with several external services, which are categorized as either **GCP Services** or **External Services** (third-party APIs).

- **GCP Services**:
  - **Firebase Authentication**: Verifies user identity and provides user metadata for RBAC.
  - **Firestore (Vector DB, RBAC, Metadata)**: Stores embeddings, user roles, and document metadata, supporting search, authentication, and temporal relevance.
  - **Pinecone (Optional Vector DB)**: An alternative to Firestore for vector storage, optimized for large-scale similarity search.
  - **Vertex AI (Foundational Model)**: Hosts the Foundational Model (e.g., PaLM 2), providing embeddings and natural language generation for the RAG pipeline.
  - **Cloud Storage**: Stores raw documents for backup or further processing.
  - **Secret Manager**: Securely stores API credentials for external services.
  - **Cloud Scheduler**: Triggers the Indexing Module nightly to keep the vector database up-to-date.
- **External Services**:
  - **Confluence API**: Provides access to Confluence pages and attachments.
  - **Google Drive API**: Provides access to Google Drive files (Docs, Sheets, PDFs).
  - **Slack API**: Provides access to Slack messages, threads, and files.

---

## How Elements Function Together

### End-to-End Workflow
Let’s walk through a typical scenario where a user (e.g., Sarah) searches for “recent project updates for Q1 2025”:

1. **User Request**:
   - Sarah sends a search query via the Angular Frontend, which makes a POST request to the FastAPI Backend’s `/search` endpoint, including her JWT token.

2. **Authentication**:
   - The **Authentication Module** receives the JWT token and uses `firebase-admin` to verify it with **Firebase Authentication**.
   - It queries **Firestore (RBAC)** to fetch Sarah’s role and permissions (e.g., she has access to project documents but not HR files).
   - The module passes Sarah’s permissions to the RAG Pipeline Module to filter search results.

3. **RAG Pipeline**:
   - The **RAG Pipeline Module** receives the query and Sarah’s permissions.
   - It uses `langchain` and `google-cloud-aiplatform` to send the query to **Vertex AI (Foundational Model)**, generating an embedding.
   - The module queries **Firestore (Vector DB)** (or **Pinecone**, if used) for the top-k documents, filtering out documents Sarah lacks permission to access (e.g., HR files).
   - The **Temporal Relevance Module** fetches the `last_modified` metadata from **Firestore (Metadata)** and applies a recency boost to the document scores.
   - The RAG Pipeline Module sends the top-k documents (now prioritized by recency) to the Foundational Model on Vertex AI, which generates a natural language answer (e.g., “The Q1 2025 project updates include…”).
   - The module returns the answer and document snippets to the Angular Frontend.

4. **Indexing (Background Process)**:
   - Overnight, **Cloud Scheduler** triggers the **Indexing Module** by invoking the `/index` endpoint.
   - The Indexing Module uses `requests`, `atlassian-python-api`, `slack_sdk`, and `google-api-python-client` to fetch new or updated content from **Confluence API**, **Google Drive API**, and **Slack API**, authenticating with credentials from **Secret Manager**.
   - It processes documents using `PyPDF2` and **Google Cloud Document AI** to extract text.
   - The module sends the text to **Vertex AI (Foundational Model)** to generate embeddings, which are stored in **Firestore (Vector DB)** or **Pinecone** along with metadata (e.g., `last_modified`, `permissions`).
   - Raw files are optionally stored in **Cloud Storage** for backup.

5. **Temporal Relevance**:
   - During the search, the **Temporal Relevance Module** ensures that recent documents (e.g., a Confluence page updated last week) are prioritized over older ones (e.g., a Slack message from 2023) by applying the recency boost.

---

## How Each Requirement Is Met

1. **RAG with Vector DBs**:
   - The **RAG Pipeline Module**, using `langchain` and `google-cloud-aiplatform`, interacts with **Vertex AI (Foundational Model)** to generate embeddings and natural language answers.
   - **Firestore** or **Pinecone** stores embeddings, enabling efficient semantic search.
   - The collaboration between the RAG Pipeline Module and the Foundational Model ensures accurate, context-aware responses.

2. **User Authentication and RBAC**:
   - The **Authentication Module**, with `firebase-admin`, verifies user identity via **Firebase Authentication** and enforces RBAC using **Firestore (RBAC)**.
   - It ensures that the RAG Pipeline Module only retrieves documents the user is authorized to access.

3. **Multi-Source Document Indexing**:
   - The **Indexing Module**, using `requests`, `atlassian-python-api`, `slack_sdk`, and `google-api-python-client`, fetches content from **Confluence API**, **Google Drive API**, and **Slack API**.
   - It processes documents with `PyPDF2` and **Google Cloud Document AI**, generates embeddings via **Vertex AI**, and stores them in **Firestore** or **Pinecone**.
   - **Cloud Scheduler** ensures regular updates, keeping the vector database current.

4. **Temporal Relevance**:
   - The **Temporal Relevance Module**, with its `Custom Scoring Logic`, uses metadata from **Firestore (Metadata)** to apply a recency boost.
   - It integrates with the RAG Pipeline Module to prioritize recent documents in search results.

---

## Why This Design?
- **Modularity**: Breaking the FastAPI Backend into modules (RAG Pipeline, Authentication, Indexing, Temporal Relevance) ensures separation of concerns, making the system easier to maintain and extend.
- **Tool Selection**:
  - `langchain` and `google-cloud-aiplatform` simplify RAG pipeline implementation and Foundational Model integration.
  - `firebase-admin` provides robust authentication with minimal setup.
  - API-specific libraries (`atlassian-python-api`, `slack_sdk`, `google-api-python-client`) streamline external integrations.
  - `PyPDF2` and **Google Cloud Document AI** handle diverse document formats efficiently.
- **External Service Integration**:
  - GCP services (Firestore, Vertex AI, Secret Manager) provide scalability, security, and managed infrastructure.
  - Third-party APIs (Confluence, Google Drive, Slack) enable multi-source indexing.
- **Performance**: FastAPI’s asynchronous capabilities ensure the backend can handle multiple requests efficiently, while tools like Pinecone and Vertex AI optimize vector search and NLP tasks.

---

## Conclusion

The FastAPI Backend’s system diagram illustrates a well-coordinated architecture where each module, supported by specific tools and external services, works together to deliver a secure, efficient, and relevant search experience. The RAG Pipeline Module drives semantic search and natural language generation, the Authentication Module ensures security, the Indexing Module keeps data fresh, and the Temporal Relevance Module prioritizes recent information—all seamlessly integrated to meet the Internal Knowledge Assistant’s requirements.